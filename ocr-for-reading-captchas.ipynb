{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OCR(Optical Character Recognition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf \n",
    "import os \n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !curl -LO https://github.com/AakashKumarNain/CaptchaCracker/raw/master/captcha_images_v2.zip\n",
    "# !unzip -qq captcha_images_v2.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains 1040 captcha files as `png` images. The label for each sample is a string,\n",
    "the name of the file (minus the file extension).\n",
    "We will map each character in the string to an integer for training the model. Similary,\n",
    "we will need to map the predictions of the model back to strings. For this purpose\n",
    "we will maintain two dictionaries, mapping characters to integers, and integers to characters,\n",
    "respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['captcha_images_v2/226md.png', 'captcha_images_v2/22d5n.png', 'captcha_images_v2/2356g.png', 'captcha_images_v2/23mdg.png', 'captcha_images_v2/23n88.png']\n",
      "['226md', '22d5n', '2356g', '23mdg', '23n88']\n",
      "Number of images found:  1040\n",
      "Number of labels found:  1040\n",
      "Number of unique characters:  19\n",
      "Characters present:  ['2', '3', '4', '5', '6', '7', '8', 'b', 'c', 'd', 'e', 'f', 'g', 'm', 'n', 'p', 'w', 'x', 'y']\n"
     ]
    }
   ],
   "source": [
    "data_dir = Path('./captcha_images_v2')\n",
    "\n",
    "# Get List of All Images\n",
    "images = sorted(list(map(str,list(data_dir.glob(pattern='*.png')))))\n",
    "print(images[:5])\n",
    "\n",
    "# Get List of All Labels\n",
    "labels = [img.split(os.path.sep)[-1].replace('.png', '') for img in images]\n",
    "print(labels[:5])\n",
    "\n",
    "# Get List of All Characters \n",
    "characters = sorted(list(set(char for label in labels for char in label)))\n",
    "\n",
    "print(\"Number of images found: \", len(images))\n",
    "print(\"Number of labels found: \", len(labels))\n",
    "print(\"Number of unique characters: \", len(characters))\n",
    "print(\"Characters present: \", characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 16\n",
    "img_width = 200\n",
    "img_height = 50\n",
    "\n",
    "# Factor by which the image is going to be downsampled\n",
    "# by the convolutional blocks. We will be using two\n",
    "# convolution blocks and each block will have\n",
    "# a pooling layer which downsample the features by a factor of 2.\n",
    "# Hence total downsampling factor would be 4.\n",
    "downsample_factor = 4 \n",
    "\n",
    "max_length = max([len(label) for label in labels])\n",
    "max_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping Characters to Integers\n",
    "char_to_num = tf.keras.layers.StringLookup(\n",
    "    vocabulary=list(characters), mask_token=None\n",
    ")\n",
    "\n",
    "# Mapping Integers back to Original Characters\n",
    "num_to_char = tf.keras.layers.StringLookup(\n",
    "    vocabulary=char_to_num.get_vocabulary(), mask_token=None, invert=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(images, labels, train_size=0.9, shuffle=True): \n",
    "    size = len(images)\n",
    "    indices = tf.keras.ops.arange(size)\n",
    "    \n",
    "    if shuffle: \n",
    "        indices = tf.keras.random.shuffle(indices)\n",
    "\n",
    "    train_samples = int(size * train_size)\n",
    "\n",
    "    X_train, Y_train = images[indices[:train_samples]], labels[indices[:train_samples]]\n",
    "    x_val, y_val = images[indices[train_samples:]], labels[indices[train_samples:]]\n",
    "\n",
    "    return X_train, Y_train, x_val, y_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
      " 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95\n",
      " 96 97 98 99], shape=(100,), dtype=int32)\n",
      "tf.Tensor(\n",
      "[84 41  8 31 93 26 78 17 18 28 29 72 23 98 15 70 53 73 57 83 71 20  2 61\n",
      " 74 13  0 43 87 24 56 58 32  1 44 14 54 51 89 50 67 30 90 27 66 80 38 45\n",
      " 22 25 92 64 99 36 68 12 94 48 81 96 65 69 55 42 33 21 79 39  9 62 19 77\n",
      "  5 60 91 40 52 76 75  7  3 59 46 47 95 35 10 37  4 97 34 88 82 63 86 49\n",
      "  6 85 16 11], shape=(100,), dtype=int32)\n",
      "90\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=int32, numpy=array([34, 88, 82, 63, 86, 49,  6, 85, 16, 11], dtype=int32)>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices = tf.keras.ops.arange(100)\n",
    "print(indices)\n",
    "indices = tf.keras.random.shuffle(indices)\n",
    "print(indices)\n",
    "sample = int(100*0.9)\n",
    "print(sample)\n",
    "\n",
    "indices[sample:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 200, 1)\n",
      "(200, 50, 1)\n",
      "[ 0 18  2  0  0  0]\n"
     ]
    }
   ],
   "source": [
    "img = tf.io.read_file(images[0])\n",
    "\n",
    "img = tf.image.decode_png(img, channels=1)\n",
    "\n",
    "img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "\n",
    "img = tf.keras.ops.image.resize(img, [img_height, img_width])\n",
    "print(img.shape)\n",
    "\n",
    "img = tf.keras.ops.transpose(img, axes=[1,0,2])\n",
    "print(img.shape)\n",
    "\n",
    "label  = char_to_num(tf.strings.unicode_split('ax3h9k',input_encoding='UTF-8'))\n",
    "\n",
    "print(label.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_single_sample(img_path, label):\n",
    "    img = tf.io.read_file(images[0])\n",
    "\n",
    "    img = tf.image.decode_png(img, channels=1)\n",
    "\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "\n",
    "    img = tf.keras.ops.image.resize(img, [img_height, img_width])\n",
    "\n",
    "    img = tf.keras.ops.transpose(img, axes=[1,0,2])\n",
    "\n",
    "    label  = char_to_num(tf.strings.unicode_split('ax3h9k',input_encoding='UTF-8'))\n",
    "\n",
    "    return {'image': img, 'label': label}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow-series",
   "language": "python",
   "name": "tensorflow-series"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
